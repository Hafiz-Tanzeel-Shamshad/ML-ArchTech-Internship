# ğŸ” Machine Learning Projects â€“ Internship Tasks

This repository contains solutions to two machine learning tasks:

1. **ğŸ“§ Email Spam Classification using Naive Bayes**
2. **ğŸ§  Handwritten Digit Classification using a Fully Connected Neural Network (FCNN)**
3. **ğŸŒ¸Iris Flower Classification**
4. **ğŸ¡California Housing Price Prediction** 
---

# ğŸ“§ Task 1: Email Spam Classification using Naive Bayes

This project builds a machine learning model to classify email or SMS messages as **spam** or **not spam** using Natural Language Processing (NLP) and the **Multinomial Naive Bayes** algorithm.

---

## ğŸš€ Overview

The objective is to:
- Preprocess raw text (lowercasing, stopword removal, stemming)
- Extract features using **TF-IDF**
- Train and evaluate a Naive Bayes model
- Output performance metrics (accuracy, precision, recall, F1-score)

---

## ğŸ§° Technologies Used

- Python
- Pandas
- Scikit-learn
- NLTK
- TF-IDF Vectorization
- Multinomial Naive Bayes Classifier

---

## ğŸ“ Dataset

We use the **UCI SMS Spam Collection Dataset**, which includes 5,574 SMS messages labeled as either `ham` or `spam`.

ğŸ“¥ Dataset Source:  
[UCI SMS Spam Collection](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection)

```python
# Example to load data
import pandas as pd
data = pd.read_csv(
    'https://raw.githubusercontent.com/justmarkham/pycon-2016-tutorial/master/data/sms.tsv',
    sep='\t', names=["label", "message"]
)

```
## ğŸ§ª Model Pipeline

### ğŸ“ Text Preprocessing
- âœ… Lowercase conversion  
- âœ… Punctuation removal  
- âœ… Stopword removal *(using NLTK)*  
- âœ… Stemming *(using PorterStemmer)*  

### ğŸ“Š Feature Extraction
- âœ… TF-IDF vectorization  

### ğŸ§  Model Training
- âœ… Train/Test Split: **80/20**  
- âœ… Model Used: **Multinomial Naive Bayes**  

### ğŸ“ˆ Evaluation Metrics
- âœ… Accuracy  
- âœ… Confusion Matrix  
- âœ… Precision  
- âœ… Recall  
- âœ… F1-score


### ğŸ“ˆ Evaluation Metrics

- **Accuracy**: `98.5%`

#### ğŸ“‹ Classification Report

| Label | Precision | Recall | F1-score | Support |
|-------|-----------|--------|----------|---------|
| **ham**  | 0.99      | 1.00   | 0.99     | 965     |
| **spam** | 1.00      | 0.90   | 0.95     | 150     |

# ğŸ§  Task 2: MNIST Digit Classification using FCNN

This project demonstrates a basic deep learning workflow using a **Fully Connected Neural Network (FCNN)** to classify handwritten digits from the **MNIST** dataset.

---

## ğŸ§¾ Objective

- ğŸ“¥ Load and preprocess the MNIST dataset  
- ğŸ—ï¸ Build a simple FCNN using TensorFlow/Keras  
- ğŸ¯ Train the model using backpropagation  
- ğŸ“ˆ Evaluate using classification metrics and visualizations  

---

## ğŸ“¦ Dataset: MNIST

- ğŸ“Š 60,000 training images  
- ğŸ“Š 10,000 testing images  
- ğŸ–¼ï¸ Grayscale 28x28 images  
- ğŸ”¢ Classes: Digits `0â€“9`  

---

## ğŸ› ï¸ Tech Stack

- ğŸ Python 3.x  
- ğŸ”§ TensorFlow / Keras  
- ğŸ“ NumPy  
- ğŸ“Š Matplotlib  

---

## ğŸ§  Model Architecture

| Layer Type      | Output Shape     | Activation     |
|-----------------|------------------|----------------|
| Flatten         | (784,)           | -              |
| Dense (128)     | (128,)           | LeakyReLU (Î±=0.1) |
| Dense (10)      | (10,)            | Softmax        |

- **Loss Function**: Categorical Crossentropy  
- **Optimizer**: Adam  
- **Metrics**: Accuracy  
- **Epochs**: 5  
- **Batch Size**: 32  
- **Validation Split**: 20% of training data  

---

## ğŸ“ˆ Results

- âœ… **Test Accuracy**: ~98%  
- ğŸ¯ Visualizations show correct predictions on test samples.

---

## ğŸ“Š Sample Output

```python
Training data shape: (60000, 28, 28)
Test data shape: (10000, 28, 28)
Test Accuracy: 0.9803
```
# ğŸŒ¸ Task 3: Iris Flower Classification 
- **Objective**: Classify iris flowers into three species (`setosa`, `versicolor`, `virginica`) based on sepal length/width and petal length/width.
- **Dataset**: [Iris dataset](https://scikit-learn.org/stable/datasets/toy_dataset.html#iris-dataset) (available in `sklearn`).
- **Algorithm Used**: Logistic Regression
- **Steps**:
  - Load and explore dataset  
  - Preprocess features and target  
  - Train/test split (80/20)  
  - Train Logistic Regression model  
  - Evaluate with accuracy & classification report  
  - Make predictions on new flower samples  

âœ… Achieved **100% accuracy** on test data.  

---

# ğŸ¡ Task 4: California Housing Price Prediction 
- **Objective**: Predict median house values in California districts using features such as median income, average rooms, population, latitude, and longitude.
- **Dataset**: [California Housing dataset](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset) (available in `sklearn`).
- **Algorithm Used**: Linear Regression
- **Steps**:
  - Load dataset  
  - Data cleaning (check missing values)  
  - Select important features  
  - Train/test split (80/20)  
  - Train Linear Regression model  
  - Evaluate with Mean Squared Error (MSE) and RÂ² score  
  - Compare predicted vs. actual prices  

âœ… Achieved **~57% RÂ² Score** (baseline model).  
## ğŸ“œ License

This project is open-source and available under the **MIT License**.

